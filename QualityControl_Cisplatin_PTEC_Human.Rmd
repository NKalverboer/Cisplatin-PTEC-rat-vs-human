---
title: "BOO2024 - QualityQontrol_Cisplatin_PTEC_Human"
author: ""
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    theme: default
    highlight: kate
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
---

# Setup {.tabset}
```{r include=FALSE, echo=TRUE, message=FALSE}
rm(list = ls()); gc()
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 80), tidy = TRUE)
```


## Load packages
### CRAN
```{r}
# Check if pacman is available and install
if(!require("pacman", quietly = T)){install.packages("pacman")}; library(pacman)

# use packman to install CRAN packages
p_load(tidyverse, ggpubr, corrr, ggfortify, ggcorrplot, ggdendro, data.table, GGally)
```


## Set directories
```{r}
# input directory
if(!dir.exists("INPUT")){
  dir.create(path = file.path(getwd(), "DATA"))
}
input_dir <- file.path(getwd(), "DATA")

# output directory
if(!dir.exists("OUTPUT")){
  dir.create(path = file.path(getwd(), "INPUT"))
}
output_dir <- file.path(getwd(), "INPUT")

# plot directory
if(!dir.exists("PLOT")){
  dir.create(path = file.path(getwd(), "PLOT"))
}
plot_dir <- file.path(getwd(), "PLOT")
```


## Load functions
```{r}
# Function: Get low cpm probes ----
get_low_cpm_probes <- function(countdata, metadata, exclude){

  if(!has_rownames(countdata)){
    countdata <- countdata %>%
      column_to_rownames(var = names(countdata %>% dplyr::select(where(is.character))))
  }

  if(!all(c("SAMPLE_ID", "MEAN_ID") %in% colnames(metadata))){
    stop("Metadata must contain columns SAMPLE_ID and MEAN_ID")
  }

  countdata <- countdata %>% dplyr::select(-contains(paste(c(exclude, collapse = "|"))))

  countdata <- data.frame(ifelse(test = countdata >= 1, yes = 1, no = 0)) %>%
    mutate(across(where(is.numeric), ~as.logical(.x)))

  countdata <- countdata %>%
    rownames_to_column(var = "GENE_SYMBOL") %>%
    pivot_longer(cols = where(is.logical), names_to = "SAMPLE_ID") %>%
    left_join(x = metadata %>%
                dplyr::select(SAMPLE_ID, MEAN_ID) %>%
                group_by(MEAN_ID) %>%
                mutate(n = n()) %>%
                ungroup(),
              by = "SAMPLE_ID") %>%
    group_by(MEAN_ID, n, GENE_SYMBOL) %>%
    summarise(value = sum(value), .groups = "drop") %>%
    filter(value <= n * 0.75)

  n_mean_id <- length(unique(countdata$MEAN_ID))

  countdata %>%
    group_by(GENE_SYMBOL) %>%
    count() %>%
    filter(n == n_mean_id) %>%
    pull(GENE_SYMBOL) %>%
    unique()
}

```


# Load data {.tabset}

## Metadata
Here you should load the metadata you obtained.
```{r}
metadata <- fread(input = file.path(input_dir, "SP0173_human_cisplatin_metadata2.csv"))
```

## Countdata
Here you should load the raw data you obtained.
```{r}
countdata_raw <- fread(input = file.path(input_dir, "SP0173_human_cisplatin_rawcounts2.csv"))
```

## Wrangle countdata and metadata
### Data inspection
Inspect the metadata object by clicking on it in the environment panel in the top right and answer the following questions.
*	How many samples are in the data? (hint: metadata$SAMPLE_ID)
```{r}
metadata$SAMPLE_ID
```

*	What cell type was used for compound exposure?*
```{r}
metadata$CELL_ID
```
*	Which time points are included?
```{r}
metadata$TIMEPOINT
```

*	Which concentrations were used for the exposure?
```{r}
metadata$DOSE
```

*	Which compounds do we consider "treatment" and "control"?
```{r}
metadata$COMPOUND
metadata$COMPOUND_ABBR
```


*	Treatment conditions are a combination of treatment, dose and time. What treatment conditions are in the data? 
```{r}
unique(expand(metadata, tidyr::nesting(COMPOUND, DOSE, TIMEPOINT)))

```
Now in inspect the raw countdata object by clicking it in the enviroment panel in the top right and answer the following question.
*	How many probes are in the data? (hint: countdata_raw$GENE_SYMBOL)
```{r}
countdata_raw$GENE_SYMBOL
```

*	Look at the dimensions of the dataframe (rows and columns). How many probes (rows) were measured?
```{r error=F,warning=F,message=F}
# We wrangle the original metadata to generate new treatment conditions and format the metadata into a clear overview. Have a look!
metadata <- metadata %>% 
  unite(col = "MEAN_ID", c(CELL_ID, COMPOUND_ABBR, TIMEPOINT , DOSE), remove = F) %>% 
  dplyr :: select(SAMPLE_ID, MEAN_ID, TIME, TIMEPOINT, REPLICATE, COMPOUND, COMPOUND_ABBR, CELL_ID, SPECIES, DOSE,  DOSE_LEVEL) 
 

# We rename the countdata column with the probes and reorder all other columns to match the metadata sample id order.  
countdata_raw <- countdata_raw %>% 
 dplyr::rename("GENE_SYMBOL" = PROBE_ID) 
#%>%
  # select(GENE_SYMBOL, metadata$SAMPLE_ID) # Reorder columns

# We print the output
 { print("Raw countdata")
  cat("\n")
  countdata_raw %>% str()
  cat("\n")
  print("Metadata")
  cat("\n")
  metadata %>% str()}

```


## QC1: Total read count filter
The total read counts filter, also called sample size filter, is applied to discart samples with a low library size.  
```{r}
library(grid)
library(extrafont)

# Load fonts 
font_import(pattern = "NotoSans")
loadfonts(device = "win") 
library(ggplot2)
library(dplyr)
library(tidyr)
library(sysfonts)
library(showtext)
# Add a custom font 
font_add_google("Noto Sans", "noto_sans")
showtext_auto()
```


```{r error=F,warning=F,message=F}
# We set the threshold to 1 million
countdata_threshold <- 1E6


# We take the sum of every individual column and transpose the data frame
size <- countdata_raw %>%
  summarise(across(where(is.numeric), sum)) %>%
  pivot_longer(cols = everything(), names_to = "SAMPLE_ID", values_to = "SAMPLE_SIZE")


# We make a bar plot using ggplot of the sample sizes with the threshold as red horizontal line for quick interpretation
ggplot(data = size, mapping = aes(x = SAMPLE_ID, y = SAMPLE_SIZE, , fill = SAMPLE_SIZE < countdata_threshold)) +
  geom_bar(stat = "identity") + 
  scale_fill_manual(values= c("TRUE" = "red", "FALSE" = "black")) +
  theme_bw() +
  theme(axis.text.x = element_text(angle=45, vjust=1, hjust=1, size = 10, family = "noto_sans", face = "bold")) +
  geom_hline(yintercept=countdata_threshold, size = 2, color = "red")+
  ggtitle("Sample size of raw countdata") + 
  ylab('Sample size')


# We identify the samples with a size (total amount of counts) below or equal to the threshold.
bad_samples = size %>% filter(SAMPLE_SIZE <= countdata_threshold)

# We filter the raw countdata for the bad samples, "fsample" in countdata_raw_fsample means filtered sample
countdata_raw_fsample = countdata_raw %>% select(-all_of(bad_samples %>% pull(SAMPLE_ID)))

# We filter the metadata for the bad samples, "fsample" in metadata_fsample means filtered sample
metadata_fsample = metadata %>% filter(!SAMPLE_ID %in% bad_samples$SAMPLE_ID)

# We print the output
  bad_samples %>% str()  
```

## QC2: Relevance filter at the CPM level

#### QC2.1: Relevance filter to be applied to normalized data: count per million normalization formula
```{r}
# CPM (Counts Per Million) are obtained by dividing counts by the library counts sum and multiplying the results by a million. 
cpm_normalization <- function(x){
(x/sum(x))*1000000
}

countdata_cpm <- data.frame(apply(countdata_raw %>% column_to_rownames(var = "GENE_SYMBOL"), 2, cpm_normalization))
```


#### QC2.2: Relevance filter
The relevance filter is applied to discart all probes that do not reach at least 1 CPM in all 3 replicates across all treatment conditions. 

```{r error=F,warning=F,message=F}

low_cpm_probes <- get_low_cpm_probes(countdata = countdata_cpm, metadata = metadata, exclude = c())
countdata_raw_fsample_fprobe = countdata_raw_fsample %>% filter(!GENE_SYMBOL %in% low_cpm_probes)

  low_cpm_probes %>% str() 
```

## QC3: Sum the raw counts of probes targeting the same gene 


```{r error=F,warning=F,message=F}
# After filtering for low cpm probes how many probes are left that target multiple genes
probe_distribution <- countdata_raw_fsample_fprobe %>% 
  separate(col = GENE_SYMBOL, into = c("GENE_SYMBOL", "PROBE"), sep = "_") %>% 
  select(GENE_SYMBOL, PROBE) %>% 
  group_by(GENE_SYMBOL) %>% 
  summarise(x = n()) %>% 
  count(x) %>% select("Probe count" = x,
                      "Unique genes" = n)

# We attach the gene symbol for the highest probe count only 
probe_distribution <- countdata_raw_fsample_fprobe %>% 
  separate(col = GENE_SYMBOL, into = c("GENE_SYMBOL", "PROBE"), sep = "_") %>% 
  select(GENE_SYMBOL, PROBE) %>% 
  group_by(GENE_SYMBOL) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  filter(n == 9) %>% # Change '9'to the highest 'Probe count' in the probe_distribution dataframe
  right_join(y = probe_distribution, by = c("n" = "Probe count")) %>% 
  arrange(n) %>% 
  select("Probe Count" = n, `Unique genes`, GENE_SYMBOL)

# We sum the probes targeting the same gene
countdata_raw_fsample_fprobe_sumprobe <- countdata_raw_fsample_fprobe %>% 
  separate(col = GENE_SYMBOL, into = c("GENE_SYMBOL", "PROBE"), sep = "_") %>% 
  group_by(GENE_SYMBOL) %>% 
  summarise(across(where(is.numeric), sum), .groups = "drop")

# We print the output
{  print(probe_distribution)
  cat("\n")
  print("Dataframe dimensions before probe sum")
  dim(countdata_raw_fsample_fprobe) %>% str()
  cat("\n")
  print("Dimensions after probe sum")
  dim(countdata_raw_fsample_fprobe_sumprobe) %>% str()
}
```


## Countdata CPM normalization

```{r error=F,warning=F,message=F}
# We use the apply function to apply our cpm_normalization column wise (indicated by the 2) over the countdata_raw_fsample_fprobe_sumprobe object
countdata_cpm_fsample_fprobe_sumprobe <- data.frame(apply(countdata_raw_fsample_fprobe_sumprobe %>% 
                                                            column_to_rownames(var = "GENE_SYMBOL"), 2, cpm_normalization))

# We print the output
{  print("Countdata raw")
  cat("\n")
  data.frame(countdata_raw_fsample_fprobe_sumprobe %>% column_to_rownames(var = "GENE_SYMBOL") %>% str())
  cat("\n")
  print("Countdata cpm normalized")
  cat("\n")
  countdata_cpm_fsample_fprobe_sumprobe %>% str()
} 
```

# Counts distribution 
We can make distribution plots to visualize the difference between the raw countdata and normalized countdata. Look at the two counts distributions.
```{r}
# Reshape raw countdata to long format. Have a look to see the change!
countdata_raw_long <- countdata_raw_fsample_fprobe_sumprobe %>%
  pivot_longer(cols = -GENE_SYMBOL, names_to = "SAMPLE_ID", values_to = "COUNTS")

# Reshape CPM normalized countdata to long format. Have a look to see the change!
countdata_cpm_long <- countdata_cpm_fsample_fprobe_sumprobe %>%
  rownames_to_column(var = "GENE_SYMBOL") %>%
  pivot_longer(cols = -GENE_SYMBOL, names_to = "SAMPLE_ID", values_to = "COUNTS")


# count distribution from the raw count data
ggplot(countdata_raw_long, aes(x = reorder(SAMPLE_ID, COUNTS, FUN = median), y = COUNTS+1)) +
        geom_boxplot(size = 0.3, outlier.size = 0.5) +
        scale_y_log10(limits = c(1, max(countdata_raw_long$COUNTS))) +
        theme_classic() +
        theme(plot.title = element_text(size=14, face="bold", vjust = 2, hjust = 0.5), 
              axis.title.x = element_text(size=12, vjust = 0.25),
              axis.title.y = element_text(size=12, vjust = 1),
              axis.text.x = element_text(size=8, angle=90, vjust=0.5, hjust=1),
              axis.text.y = element_text(size=12)) +
        ggtitle("Distribution raw counts") + ylab('counts') + xlab("sampleID")

# count distribution from the CPM normalized count data
ggplot(countdata_cpm_long, aes(x = reorder(SAMPLE_ID, COUNTS, FUN = median), y = COUNTS)) +
        geom_boxplot(size = 0.3, outlier.size = 0.5) +
  scale_y_log10(limits = c(1, max(countdata_cpm_long$COUNTS))) +
        theme_classic() +
        theme(plot.title = element_text(size=14, face="bold", vjust = 2, hjust = 0.5), 
              axis.title.x = element_text(size=12, vjust = 0.25),
              axis.title.y = element_text(size=12, vjust = 1),
              axis.text.x = element_text(size=8, angle=90, vjust=0.5, hjust=1),
              axis.text.y = element_text(size=12)) +
        ggtitle("Distribution CPM Normalized counts") + ylab('CPM Normalized counts') + xlab("sampleID")

```


## PCA plot and correlation plot 

### Principal component analysis on CPM normalized counts
We make a PCA plot to help detect outliers that behave differently from the majority of samples. 
```{r error=F,warning=F,message=F}
# We transpose the prepared count data: sampleIDs from the column names to a single row, and all GENE_SYMBOL count data to an individual column
pca_data <- countdata_cpm_fsample_fprobe_sumprobe %>% 
  rownames_to_column(var = "GENE_SYMBOL") %>% 
  pivot_longer(-GENE_SYMBOL) %>% 
  pivot_wider(names_from = GENE_SYMBOL, values_from = value) %>% 
  rename(SAMPLE_ID = name) %>% # change 'name' to 'SAMPLE_ID' for clarity
  left_join(metadata_fsample %>% select(SAMPLE_ID, MEAN_ID, REPLICATE), by = "SAMPLE_ID") %>%
  mutate(REPLICATE = as.character(REPLICATE))


# We perform pca analysis on the numerical columns (the count data)
pca_object = prcomp(pca_data %>% select(where(is.numeric)), center = F, scale. = F)

# We print the output
{  print("First 10 column of the count data")
  print(pca_data %>% head() %>% select(1:10))
  cat("\n")
  autoplot(object = pca_object, data = pca_data, colour = "REPLICATE",   size = 2) + 
    theme_bw()
}
```


```{r error=F,warning=F,message=F}
# We rescale the x and y coordinates to -1 to 1 and print the new plot
autoplot(object = pca_object, data = pca_data, colour = "REPLICATE",   size = 2) + 
  theme_bw() + coord_cartesian(xlim = c(-1,1), ylim = c(-1,1))

```


### Replicate correlation 

```{r}
library(tidyr)
library(dplyr)
library(ggplot2)
# Calculate correlation
correlation_data <- countdata_cpm_fsample_fprobe_sumprobe %>%
  rownames_to_column(var = "GENE_SYMBOL") %>%
  pivot_longer(-GENE_SYMBOL, names_to = "SAMPLE_ID") %>%
  left_join(metadata_fsample, by = "SAMPLE_ID") %>%
  select(GENE_SYMBOL, SAMPLE_ID, MEAN_ID, value) %>%
  nest_by(MEAN_ID) %>%
  mutate(data = list(data %>% pivot_wider(names_from = SAMPLE_ID, values_from = value)))

# Extract correlation
correlation_data <- correlation_data %>%
  mutate(cor_matrix = list(cor(select(data, -GENE_SYMBOL), use = "complete.obs"))) %>%
  mutate(cor_values = list(as.data.frame(as.table(cor_matrix)))) %>%
  unnest(cor_values)

# Filter--> keep unique pairs
correlation_data <- correlation_data %>%
  filter(Var1 != Var2) %>%
  group_by(MEAN_ID) %>%
  mutate(pair = paste(pmin(Var1, Var2), pmax(Var1, Var2), sep = "-")) %>%
  distinct(MEAN_ID, pair, Freq)

# Mean correlation for each treatment condition
mean_correlations <- correlation_data %>%
  group_by(MEAN_ID) %>%
  summarise(mean_correlation = mean(Freq))

order <- c("HPPTEC_NaCl_8hr_0.9", 
           "HPPTEC_CSP_8hr_2.5",  
           "HPPTEC_CSP_8hr_10",   
           "HPPTEC_CSP_8hr_50",   
           "HPPTEC_NaCl_24hr_0.9",
           "HPPTEC_CSP_24hr_2.5", 
           "HPPTEC_CSP_24hr_10",  
           "HPPTEC_CSP_24hr_50",  
           "HPPTEC_NaCl_72hr_0.9",
           "HPPTEC_CSP_72hr_2.5", 
           "HPPTEC_CSP_72hr_10",  
           "HPPTEC_CSP_72hr_50")

mean_correlations$MEAN_ID <- factor(mean_correlations$MEAN_ID, levels = order)
correlation_data$MEAN_ID <- factor(correlation_data$MEAN_ID, levels = order)
```

```{r}
ggplot(correlation_data, aes(MEAN_ID, Freq)) + 
  geom_point(aes(color = Freq < 0.75)) +
  scale_color_manual(values = c("TRUE" = "red", "FALSE" = "black")) + 
  geom_hline(yintercept = 0.75, color = "red") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, face = "bold", family = "noto_sans", size = 12), 
        axis.text.y = element_text(size = 10, family = "noto_sans", face = "bold"), 
        plot.title = element_text(family = "noto_sans", size = 15, face = "bold"),
        axis.title.x = element_text(family= "noto_sans", size = 12, face = "bold"),
        axis.title.y = element_text(family= "noto_sans", size = 12, face = "bold")
        ) +
  labs(x = "Treatment Condition", y = "Mean Correlation Coefficient", title = "Mean Replicate Correlations")

```

```{r}

# Filter--> threshold at 0.75
correlation_data_above_threshold <- correlation_data %>%
  filter(Freq >= 0.75)


correlation_data_above_threshold$MEAN_ID <- factor(correlation_data_above_threshold$MEAN_ID, levels = order)

# Scatterolot using data above threshold
ggplot(correlation_data_above_threshold, aes(MEAN_ID, Freq)) + 
  geom_point(color = "black") +
  geom_hline(yintercept = 0.75, color = "red") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, face = "bold", family = "noto_sans", size = 12),
        axis.text.y = element_text(face = "bold", family = "noto_sans", size = 12),
        plot.title = element_text(family = "noto_sans", size = 15, face = "bold"),
        axis.title.x = element_text(family= "noto_sans", size = 12, face = "bold"),
        axis.title.y = element_text(family= "noto_sans", size = 12, face = "bold")
        ) +
  labs(x = "Treatment Condition", y = "Mean Correlation Coefficient", title = "Mean Replicate Correlations by Treatment Condition")
```



```{r}

# Mean correlation barplot
ggplot(mean_correlations, aes(x = MEAN_ID, y = mean_correlation, fill = mean_correlation <0.75 )) +
  geom_bar(stat = "identity", color = "black") +
  scale_fill_manual(values= c("TRUE" = "red", "FALSE" = "black", labels = c("Below threshold", "Above threshold"))) + 
  geom_hline(yintercept = 0.75, color = "red") +
  labs(x = "Treatment Condition", y = "Mean Correlation Coefficient", title = "Mean Replicate Correlations by Treatment Condition") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
```{r}
# Mean correlation for each treatment condition
mean_correlations2 <- correlation_data_above_threshold %>%
  group_by(MEAN_ID) %>%
  summarise(mean_correlation2 = mean(Freq))

order <- c("HPPTEC_NaCl_8hr_0.9", 
           "HPPTEC_CSP_8hr_2.5",  
           "HPPTEC_CSP_8hr_10",   
           "HPPTEC_CSP_8hr_50",   
           "HPPTEC_NaCl_24hr_0.9",
           "HPPTEC_CSP_24hr_2.5", 
           "HPPTEC_CSP_24hr_10",  
           "HPPTEC_CSP_24hr_50",  
           "HPPTEC_NaCl_72hr_0.9",
           "HPPTEC_CSP_72hr_2.5", 
           "HPPTEC_CSP_72hr_10",  
           "HPPTEC_CSP_72hr_50")

mean_correlations2$MEAN_ID <- factor(mean_correlations2$MEAN_ID, levels = order)
correlation_data$MEAN_ID <- factor(correlation_data$MEAN_ID, levels = order)


# Barplot mean correlation
ggplot(mean_correlations2, aes(x = MEAN_ID, y = mean_correlation2, fill = mean_correlation2 <0.75 )) +
  geom_bar(stat = "identity", color = "black") +
  scale_fill_manual(values= c("TRUE" = "red", "FALSE" = "black", labels = c("Below threshold", "Above threshold"))) + 
  geom_hline(yintercept = 0.75, color = "red") +
  labs(x = "Treatment Condition", y = "Mean Correlation Coefficient", title = "Mean Replicate Correlations by Treatment Condition 2") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


```{r error=F,warning=F,message=F}
# We combine the replicates from the same treatment condition and perform replicate correlation using the ggpairs function
correlation = countdata_cpm_fsample_fprobe_sumprobe %>%
  rownames_to_column(var = "GENE_SYMBOL") %>%
  pivot_longer(-GENE_SYMBOL,names_to = "SAMPLE_ID") %>%
  left_join(metadata_fsample, by = "SAMPLE_ID") %>%
  select(GENE_SYMBOL, SAMPLE_ID, MEAN_ID, value) %>% 
  nest_by(MEAN_ID) %>% 
  mutate(data = list(data %>% pivot_wider(names_from = SAMPLE_ID, values_from = value)),
         plot = list(ggpairs(data = data %>% select(-GENE_SYMBOL),upper = list(continuous = "cor")) + theme_bw())) 


  for(i in 1:12){
    print(correlation$MEAN_ID[[i]])
    print(correlation$plot[[i]])
  }
  
```


#### General CPM correlation plot

```{r}
countdata_cpm_threshold <- 
  subset(countdata_cpm_fsample_fprobe_sumprobe, select = -c(S_0.9pc_NaCl_72_h_P2, S_2.5_uM_Cisplatin_24_h_P1, S_10_uM_Cisplatin_72_h_P2 )) 
  
```
 
 
```{r error=F,warning=F,message=F}
# We correlate all the count data and generate a correlation plot
plot = ggcorrplot(corr = correlate(countdata_cpm_threshold, diagonal = 1, quiet = T) %>% 
                    column_to_rownames(var = "term"), lab = TRUE, hc.order = T) +
  scale_fill_gradient2(limit = c(0.7,1), low = "white", high =  "red", mid = "lightblue", midpoint = 0.85) +
   theme(axis.text.x = element_text(size = 6), axis.text.y = element_text(size = 6))
plot$layers[[2]]$aes_params$size <- 1.3

  plot
```
# Ordered based on plate number (without the replicates with low correlation)

```{r}
library(tidyverse)
library(ggcorrplot)
library(corrr)

order <- c("S_0.9pc_NaCl_8_h_P1", "S_2.5_uM_Cisplatin_8_h_P1", "S_10_uM_Cisplatin_8_h_P1", "S_50_uM_Cisplatin_8_h_P1", 
             "S_10_uM_Cisplatin_24_h_P1", "S_50_uM_Cisplatin_24_h_P1",
           "S_0.9pc_NaCl_72_h_P1", "S_2.5_uM_Cisplatin_72_h_P1", "S_10_uM_Cisplatin_72_h_P1", "S_50_uM_Cisplatin_72_h_P1", 
           "S_0.9pc_NaCl_8_h_P2", "S_2.5_uM_Cisplatin_8_h_P2", "S_10_uM_Cisplatin_8_h_P2", "S_50_uM_Cisplatin_8_h_P2",
          "S_0.9pc_NaCl_24_h_P2", "S_2.5_uM_Cisplatin_24_h_P2", "S_10_uM_Cisplatin_24_h_P2", "S_50_uM_Cisplatin_24_h_P2",
            "S_2.5_uM_Cisplatin_72_h_P2",   "S_50_uM_Cisplatin_72_h_P2",
         "S_0.9pc_NaCl_8_h_P3", "S_2.5_uM_Cisplatin_8_h_P3", "S_10_uM_Cisplatin_8_h_P3", "S_50_uM_Cisplatin_8_h_P3", 
           "S_0.9pc_NaCl_24_h_P3", "S_2.5_uM_Cisplatin_24_h_P3", "S_10_uM_Cisplatin_24_h_P3", "S_50_uM_Cisplatin_24_h_P3",
           "S_0.9pc_NaCl_72_h_P3", "S_2.5_uM_Cisplatin_72_h_P3", "S_10_uM_Cisplatin_72_h_P3", "S_50_uM_Cisplatin_72_h_P3"  )

# Correlationmatrix
correlation_matrix <- correlate(countdata_cpm_threshold, diagonal = 1, quiet = TRUE) %>%
  column_to_rownames(var = "term")

# Control of elements in "order"
missing_columns <- setdiff(order, colnames(correlation_matrix))
if (length(missing_columns) > 0) {
  stop("De volgende kolommen ontbreken in de correlatiematrix: ", paste(missing_columns, collapse = ", "))
}

correlation_matrix <- correlation_matrix[order, order]

# Correlationplot
plot <- ggcorrplot(correlation_matrix, lab = TRUE) +
  scale_fill_gradient2(limit = c(0.7, 1), low = "white", high = "red", mid = "lightblue", midpoint = 0.85) +
  theme(axis.text.x = element_text(size = 6, angle = 90, hjust = 1, vjust = 0.5),
        axis.text.y = element_text(size = 6))


plot$layers[[2]]$aes_params$size <- 1.3


print(plot)
```

```{r}
# Install the pheatmap package 
if (!requireNamespace("pheatmap", quietly = TRUE)) {
  install.packages("pheatmap")
}

library(pheatmap)
library(dplyr)
library(corrr)

# Calculate correlation matrix
correlation_matrix <- correlate(countdata_cpm_threshold, diagonal = 1, quiet = TRUE) %>%
                      column_to_rownames(var = "term")

# Heatmap
pheatmap(correlation_matrix,
         display_numbers = TRUE,               # Display the correlation values
         cluster_rows = TRUE,                  # Perform hierarchical clustering on rows
         cluster_cols = TRUE,                  # Perform hierarchical clustering on columns
         color = colorRampPalette(c("white", "lightblue", "red"))(50),  
         breaks = seq(0.8, 1, length.out = 51), 
         fontsize = 6,                        
         fontsize_number = 4,                  
         angle_col = "45")                    

```



# Remove the replicates with low correlation (below threshold)
```{r}
countdata_raw_threshold <- subset(countdata_raw_fsample_fprobe_sumprobe, select = -c(S_0.9pc_NaCl_72_h_P2, S_2.5_uM_Cisplatin_24_h_P1, S_10_uM_Cisplatin_72_h_P2 ))
```

```{r}
rows_to_remove <- c( "S_0.9pc_NaCl_72_h_P2", "S_2.5_uM_Cisplatin_24_h_P1", "S_10_uM_Cisplatin_72_h_P2")
metadata_threshold <- metadata_fsample %>% 
  filter(! SAMPLE_ID %in% rows_to_remove)
```

# Save output
We save our preprocessed raw count data (`countdata_raw_fsample_fprobe_sumprobe`) and metadata (`metadata_fsample`) in preperation for the DEG analysis. Since the DESeq2 package used for the DEG analysis performs its own normalization, we specifically save the raw count data rather than the normalized count data.
```{r}
# Save your countdata
write_csv(countdata_raw_threshold, file.path(output_dir, paste0(gsub( "-", "", Sys.Date()), "_filtered_countdata_raw_processedHuman2.csv"))) 

# Save your metadata
write_csv(metadata_threshold, file.path(output_dir, paste0(gsub( "-", "", Sys.Date()), "_filtered_metadata_processedHuman2.csv"))) 
```
